\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{wired-facebook}
\citation{warner2012detecting}
\citation{ishisaka2010detecting}
\citation{goyal2013peer}
\citation{Razavi2010}
\citation{goyal2013peer}
\citation{kaggle2012}
\citation{ishisaka2010detecting}
\citation{DBLP:conf/www/NobataTTMC16}
\citation{Djuric:2015:HSD:2740908.2742760}
\citation{DBLP:conf/www/NobataTTMC16}
\citation{kaggle-data}
\citation{Razavi2010}
\citation{Razavi2010}
\citation{warner2012detecting}
\citation{goyal2013peer}
\citation{nahar2013effective}
\citation{reynolds2011using}
\citation{Kontostathis:2013:DCQ:2464464.2464499}
\citation{DBLP:conf/www/NobataTTMC16}
\citation{chen2012detecting}
\citation{le2014distributed}
\citation{DBLP:conf/www/NobataTTMC16}
\citation{Djuric:2015:HSD:2740908.2742760}
\citation{techcrunch-facebook}
\citation{formspring-data}
\citation{reddit-data}
\citation{kaggle-data}
\citation{kaggle-data}
\citation{DBLP:conf/www/NobataTTMC16}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Breakdown of datasets}}{2}{table.1}}
\newlabel{dataset-breakdown}{{1}{2}{Dataset Description}{table.1}{}}
\citation{Razavi2010}
\newlabel{network-topology}{{}{4}{Character LSTM}{section*.9}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Topology of Char-LSTM}}{4}{figure.1}}
\citation{Djuric:2015:HSD:2740908.2742760}
\citation{warner2012detecting}
\citation{DBLP:conf/www/NobataTTMC16}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Results}}{6}{table.2}}
\newlabel{results}{{2}{6}{Results}{table.2}{}}
\newlabel{size-matters}{{}{6}{Recurrent Architectures}{section*.17}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Performance of different sized models on validation set (5 epoch moving average). Large models were stopped after 400 epochs when performance began to decline.}}{6}{figure.2}}
\citation{warner2012detecting}
\newlabel{effect-regularization}{{}{7}{Recurrent Architectures}{figure.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces The char-LSTM seems to learn some suffixes (-cker) as well as profanity}}{7}{figure.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces char-LSTM as word}}{8}{figure.4}}
\citation{*}
\bibstyle{unsrt}
\bibdata{papers}
\bibcite{wired-facebook}{1}
\bibcite{warner2012detecting}{2}
\bibcite{ishisaka2010detecting}{3}
\bibcite{goyal2013peer}{4}
\bibcite{Razavi2010}{5}
\bibcite{kaggle2012}{6}
\bibcite{DBLP:conf/www/NobataTTMC16}{7}
\bibcite{Djuric:2015:HSD:2740908.2742760}{8}
\bibcite{kaggle-data}{9}
\bibcite{nahar2013effective}{10}
\bibcite{reynolds2011using}{11}
\bibcite{Kontostathis:2013:DCQ:2464464.2464499}{12}
\bibcite{chen2012detecting}{13}
\bibcite{le2014distributed}{14}
\bibcite{techcrunch-facebook}{15}
\bibcite{formspring-data}{16}
\bibcite{reddit-data}{17}
\bibcite{sculley2008advances}{18}
\@writefile{toc}{\contentsline {section}{Appendices}{10}{section*.24}}
